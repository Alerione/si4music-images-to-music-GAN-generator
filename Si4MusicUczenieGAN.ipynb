{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Si4MusicUczenieGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNky/ZcY9dJ7UBd6GB5+YPe"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tUV7DdQ0nH4r"},"source":["<h1>Projekt <b>Sztuczna inteligencja w muzyce</b> - zamiana obrazów w midi</h1>\r\n"]},{"cell_type":"markdown","metadata":{"id":"i_B8ZnQwnB8Q"},"source":["**Import** danych z dysku google:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si7YLubUGYW1","executionInfo":{"status":"ok","timestamp":1611041340548,"user_tz":-60,"elapsed":25096,"user":{"displayName":"Jakub Gołębiowski","photoUrl":"","userId":"05324360243394947978"}},"outputId":"ff308b60-d2c6-4268-c201-f0ccda104d2c"},"source":["import numpy as np\r\n","\r\n","try:\r\n","    from google.colab import drive\r\n","    drive.mount('/content/drive', force_remount=True)\r\n","    COLAB = True\r\n","    print(\"Note: using Google CoLab\")\r\n","    %tensorflow_version 2.x\r\n","except:\r\n","    print(\"Note: not using Google CoLab\")\r\n","    COLAB = False\r\n","# load numpy array from npy file\r\n","\r\n","from numpy import load\r\n","# load array\r\n","imgs = load('/content/drive/My Drive/Ai/imgs7090x225.npy')\r\n","midis = load('/content/drive/My Drive/Ai/midis18x18.npy')\r\n","\r\n","#midis.insert(midi)\r\n","# print the array\r\n","print(imgs.shape)\r\n","print(midis.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Note: using Google CoLab\n","(7090, 225)\n","(7090, 18, 18)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MFS1DpGsins5"},"source":["Generowanie dyskryminatora, generatora i uczenie modelu"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDD7f6c55tlU","executionInfo":{"status":"ok","timestamp":1611041442035,"user_tz":-60,"elapsed":47033,"user":{"displayName":"Jakub Gołębiowski","photoUrl":"","userId":"05324360243394947978"}},"outputId":"5a8e064e-2a0c-4387-fb98-d80b4f4f4c9e"},"source":["\r\n","#This part of code original author: \"Sreenivas Bhattiprolu\" -> https://github.com/bnsreenu/python_for_microscopists/blob/master/125_126_GAN_training_mnist.py\r\n","\r\n","#I copied code and made some changes:\r\n","# -other output ((1,18,18,1) matrix)\r\n","# -other noise (not random but based on real input, classificated by users (7090 input vectors)) in format (7090, 225)\r\n","\r\n","\r\n","from keras.layers import Input, Dense, Reshape, Flatten\r\n","from keras.layers import BatchNormalization\r\n","from keras.layers.advanced_activations import LeakyReLU\r\n","from keras.models import Sequential, Model\r\n","from keras.optimizers import Adam\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","\r\n","#midi output size:\r\n","img_rows = 18\r\n","img_cols = 18\r\n","channels = 1\r\n","\r\n","#noise vector (our grayscaled images) size:\r\n","noise_size = 15*15\r\n","\r\n","img_shape = (img_rows, img_cols, channels)\r\n","\r\n","##########################################################################\r\n","#Given input of noise (latent) vector, the Generator produces an image.\r\n","def build_generator():\r\n","\r\n","    noise_shape = (15*15,) #1D array of size 15*15 (latent vector / noise)\r\n","\r\n","#Define your generator network \r\n","#Here we are only using Dense layers. But network can be complicated based\r\n","#on the application. For example, you can use VGG for super res. GAN.         \r\n","\r\n","    model = Sequential()\r\n","\r\n","    model.add(Dense(256, input_shape=noise_shape))\r\n","    model.add(LeakyReLU(alpha=0.2))\r\n","    model.add(BatchNormalization(momentum=0.8))\r\n","    model.add(Dense(512))\r\n","    model.add(LeakyReLU(alpha=0.2))\r\n","    model.add(BatchNormalization(momentum=0.8))\r\n","    model.add(Dense(1024))\r\n","    model.add(LeakyReLU(alpha=0.2))\r\n","    model.add(BatchNormalization(momentum=0.8))\r\n","    \r\n","    model.add(Dense(np.prod(img_shape), activation='tanh'))\r\n","    model.add(Reshape(img_shape))\r\n","\r\n","    model.summary()\r\n","\r\n","    noise = Input(shape=noise_shape)\r\n","    img = model(noise)    #Generated image\r\n","\r\n","    return Model(noise, img)\r\n","\r\n","#Alpha — α is a hyperparameter which controls the underlying value to which the\r\n","#function saturates negatives network inputs.\r\n","#Momentum — Speed up the training\r\n","##########################################################################\r\n","\r\n","#Given an input image, the Discriminator outputs the likelihood of the image being real.\r\n","    #Binary classification - true or false (we're calling it validity)\r\n","\r\n","def build_discriminator():\r\n","\r\n","\r\n","    model = Sequential()\r\n","\r\n","    model.add(Flatten(input_shape=img_shape))\r\n","    model.add(Dense(512))\r\n","    model.add(LeakyReLU(alpha=0.2))\r\n","    model.add(Dense(256))\r\n","    model.add(LeakyReLU(alpha=0.2))\r\n","    model.add(Dense(1, activation='sigmoid'))\r\n","    model.summary()\r\n","\r\n","    img = Input(shape=img_shape)\r\n","    validity = model(img)\r\n","\r\n","    return Model(img, validity)\r\n","#The validity is the Discriminator’s guess of input being real or not.\r\n","\r\n","\r\n","#Now that we have constructed our two models it’s time to pit them against each other.\r\n","#We do this by defining a training function, loading the data set, re-scaling our training\r\n","#images and setting the ground truths. \r\n","def train(midis, imgs, epochs, batch_size=128):\r\n","\r\n","    # Load the dataset\r\n","    #(X_train, _), (_, _) = mnist.load_data()\r\n","    X_train = midis\r\n","    noise2 = imgs\r\n","    # Convert to float and Rescale -1 to 1 (Can also do 0 to 1)\r\n","    X_train = ((X_train.astype(np.float32) + 128) - 544 ) / 544\r\n","    noise2 = (noise2.astype(np.float32)) / 255\r\n","\r\n","#Add channels dimension. As the input to our gen and discr. has a shape 28x28x1.\r\n","    X_train = np.expand_dims(X_train, axis=3) \r\n","\r\n","    half_batch = int(batch_size / 2)\r\n","\r\n","\r\n","#We then loop through a number of epochs to train our Discriminator by first selecting\r\n","#a random batch of images from our true dataset, generating a set of images from our\r\n","#Generator, feeding both set of images into our Discriminator, and finally setting the\r\n","#loss parameters for both the real and fake images, as well as the combined loss. \r\n","    \r\n","    for epoch in range(epochs):\r\n","\r\n","        # ---------------------\r\n","        #  Train Discriminator\r\n","        # ---------------------\r\n","\r\n","        # Select a random half batch of real images\r\n","        idx = np.random.randint(0, X_train.shape[0], half_batch)\r\n","        imgs = X_train[idx]\r\n","\r\n"," \r\n","        noise = noise2[idx]#np.random.normal(0, 1, (half_batch, 15*15))\r\n","\r\n","        # Generate a half batch of fake images\r\n","        gen_imgs = generator.predict(noise)\r\n","\r\n","        # Train the discriminator on real and fake images, separately\r\n","        #Research showed that separate training is more effective. \r\n","        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\r\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\r\n","    #take average loss from real and fake images. \r\n","    #\r\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \r\n","\r\n","#And within the same loop we train our Generator, by setting the input noise and\r\n","#ultimately training the Generator to have the Discriminator label its samples as valid\r\n","#by specifying the gradient loss.\r\n","        # ---------------------\r\n","        #  Train Generator\r\n","        # ---------------------\r\n","#Create noise vectors as input for generator. \r\n","#Create as many noise vectors as defined by the batch size. \r\n","#Based on normal distribution. Output will be of size (batch size, 100)\r\n","        noise = np.random.normal(0, 1, (batch_size, 15*15)) \r\n","\r\n","        # The generator wants the discriminator to label the generated samples\r\n","        # as valid (ones)\r\n","        #This is where the genrator is trying to trick discriminator into believing\r\n","        #the generated image is true (hence value of 1 for y)\r\n","        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\r\n","\r\n","        # Generator is part of combined where it got directly linked with the discriminator\r\n","        # Train the generator with noise as x and 1 as y. \r\n","        # Again, 1 as the output as it is adversarial and if generator did a great\r\n","        #job of folling the discriminator then the output would be 1 (true)\r\n","        g_loss = combined.train_on_batch(noise, valid_y)\r\n","\r\n","\r\n","#Additionally, in order for us to keep track of our training process, we print the\r\n","#progress and save the sample image output depending on the epoch interval specified.  \r\n","# Plot the progress\r\n","        \r\n","        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\r\n","\r\n","\r\n","##############################################################################\r\n","\r\n","#Let us also define our optimizer for easy use later on.\r\n","#That way if you change your mind, you can change it easily here\r\n","optimizer = Adam(0.0002, 0.7)  #Learning rate and momentum.\r\n","\r\n","# Build and compile the discriminator first. \r\n","#Generator will be trained as part of the combined model, later. \r\n","#pick the loss function and the type of metric to keep track.                 \r\n","#Binary cross entropy as we are doing prediction and it is a better\r\n","#loss function compared to MSE or other. \r\n","discriminator = build_discriminator()\r\n","discriminator.compile(loss='binary_crossentropy',\r\n","    optimizer=optimizer,\r\n","    metrics=['accuracy'])\r\n","\r\n","#build and compile our Discriminator, pick the loss function\r\n","\r\n","#SInce we are only generating (faking) images, let us not track any metrics.\r\n","generator = build_generator()\r\n","generator.compile(loss='binary_crossentropy', optimizer=optimizer)\r\n","\r\n","##This builds the Generator and defines the input noise. \r\n","#In a GAN the Generator network takes noise z as an input to produce its images.  \r\n","z = Input(shape=(15*15,))   #Our random input to the generator\r\n","img = generator(z)\r\n","\r\n","#This ensures that when we combine our networks we only train the Generator.\r\n","#While generator training we do not want discriminator weights to be adjusted. \r\n","#This Doesn't affect the above descriminator training.     \r\n","discriminator.trainable = False  \r\n","\r\n","#This specifies that our Discriminator will take the images generated by our Generator\r\n","#and true dataset and set its output to a parameter called valid, which will indicate\r\n","#whether the input is real or not.  \r\n","valid = discriminator(img)  #Validity check on the generated image\r\n","\r\n","\r\n","#Here we combined the models and also set our loss function and optimizer. \r\n","#Again, we are only training the generator here. \r\n","#The ultimate goal here is for the Generator to fool the Discriminator.  \r\n","# The combined model  (stacked generator and discriminator) takes\r\n","# noise as input => generates images => determines validity\r\n","\r\n","combined = Model(z, valid)\r\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer)\r\n","\r\n","\r\n","train(midis, imgs, epochs=1000, batch_size=32)\r\n","\r\n","#Save model for future use to generate fake images\r\n","#Not tested yet... make sure right model is being saved..\r\n","#Compare with GAN4\r\n","\r\n","generator.save('/content/drive/My Drive/Ai/generator_model_final_1K.h5')  #Test the model on GAN4_predict...\r\n","#Change epochs back to 30K"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 324)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               166400    \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 297,985\n","Trainable params: 297,985\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 256)               57856     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 256)               1024      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              525312    \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 324)               332100    \n","_________________________________________________________________\n","reshape (Reshape)            (None, 18, 18, 1)         0         \n","=================================================================\n","Total params: 1,054,020\n","Trainable params: 1,050,436\n","Non-trainable params: 3,584\n","_________________________________________________________________\n","0 [D loss: 0.568292, acc.: 50.00%] [G loss: 0.477104]\n","1 [D loss: 0.393283, acc.: 100.00%] [G loss: 0.482606]\n","2 [D loss: 0.308268, acc.: 100.00%] [G loss: 0.464692]\n","3 [D loss: 0.223813, acc.: 100.00%] [G loss: 0.507479]\n","4 [D loss: 0.145112, acc.: 100.00%] [G loss: 0.490490]\n","5 [D loss: 0.086059, acc.: 100.00%] [G loss: 0.461060]\n","6 [D loss: 0.051090, acc.: 100.00%] [G loss: 0.452973]\n","7 [D loss: 0.029042, acc.: 100.00%] [G loss: 0.465552]\n","8 [D loss: 0.021453, acc.: 100.00%] [G loss: 0.445077]\n","9 [D loss: 0.015125, acc.: 100.00%] [G loss: 0.432887]\n","10 [D loss: 0.012994, acc.: 100.00%] [G loss: 0.445143]\n","11 [D loss: 0.011441, acc.: 100.00%] [G loss: 0.435581]\n","12 [D loss: 0.010684, acc.: 100.00%] [G loss: 0.402001]\n","13 [D loss: 0.009651, acc.: 100.00%] [G loss: 0.418261]\n","14 [D loss: 0.009596, acc.: 100.00%] [G loss: 0.376440]\n","15 [D loss: 0.009797, acc.: 100.00%] [G loss: 0.373552]\n","16 [D loss: 0.009663, acc.: 100.00%] [G loss: 0.378841]\n","17 [D loss: 0.010482, acc.: 100.00%] [G loss: 0.378114]\n","18 [D loss: 0.010801, acc.: 100.00%] [G loss: 0.343710]\n","19 [D loss: 0.010989, acc.: 100.00%] [G loss: 0.348177]\n","20 [D loss: 0.007148, acc.: 100.00%] [G loss: 0.334756]\n","21 [D loss: 0.006109, acc.: 100.00%] [G loss: 0.347577]\n","22 [D loss: 0.005490, acc.: 100.00%] [G loss: 0.302754]\n","23 [D loss: 0.005896, acc.: 100.00%] [G loss: 0.338300]\n","24 [D loss: 0.005289, acc.: 100.00%] [G loss: 0.337913]\n","25 [D loss: 0.004725, acc.: 100.00%] [G loss: 0.301879]\n","26 [D loss: 0.005445, acc.: 100.00%] [G loss: 0.296443]\n","27 [D loss: 0.005082, acc.: 100.00%] [G loss: 0.318185]\n","28 [D loss: 0.005179, acc.: 100.00%] [G loss: 0.300089]\n","29 [D loss: 0.005603, acc.: 100.00%] [G loss: 0.268761]\n","30 [D loss: 0.004872, acc.: 100.00%] [G loss: 0.238124]\n","31 [D loss: 0.005119, acc.: 100.00%] [G loss: 0.274892]\n","32 [D loss: 0.004094, acc.: 100.00%] [G loss: 0.248041]\n","33 [D loss: 0.003987, acc.: 100.00%] [G loss: 0.250732]\n","34 [D loss: 0.003274, acc.: 100.00%] [G loss: 0.258762]\n","35 [D loss: 0.003695, acc.: 100.00%] [G loss: 0.231990]\n","36 [D loss: 0.003807, acc.: 100.00%] [G loss: 0.262118]\n","37 [D loss: 0.003490, acc.: 100.00%] [G loss: 0.227656]\n","38 [D loss: 0.003006, acc.: 100.00%] [G loss: 0.230597]\n","39 [D loss: 0.002413, acc.: 100.00%] [G loss: 0.193151]\n","40 [D loss: 0.002333, acc.: 100.00%] [G loss: 0.201326]\n","41 [D loss: 0.003223, acc.: 100.00%] [G loss: 0.189909]\n","42 [D loss: 0.003674, acc.: 100.00%] [G loss: 0.204765]\n","43 [D loss: 0.002953, acc.: 100.00%] [G loss: 0.198826]\n","44 [D loss: 0.002081, acc.: 100.00%] [G loss: 0.223604]\n","45 [D loss: 0.002772, acc.: 100.00%] [G loss: 0.175866]\n","46 [D loss: 0.004240, acc.: 100.00%] [G loss: 0.209853]\n","47 [D loss: 0.003827, acc.: 100.00%] [G loss: 0.177871]\n","48 [D loss: 0.003055, acc.: 100.00%] [G loss: 0.175776]\n","49 [D loss: 0.002661, acc.: 100.00%] [G loss: 0.191996]\n","50 [D loss: 0.002747, acc.: 100.00%] [G loss: 0.188934]\n","51 [D loss: 0.002834, acc.: 100.00%] [G loss: 0.178469]\n","52 [D loss: 0.002718, acc.: 100.00%] [G loss: 0.207260]\n","53 [D loss: 0.004025, acc.: 100.00%] [G loss: 0.173565]\n","54 [D loss: 0.005359, acc.: 100.00%] [G loss: 0.199084]\n","55 [D loss: 0.004206, acc.: 100.00%] [G loss: 0.180110]\n","56 [D loss: 0.003315, acc.: 100.00%] [G loss: 0.162693]\n","57 [D loss: 0.002158, acc.: 100.00%] [G loss: 0.180498]\n","58 [D loss: 0.001790, acc.: 100.00%] [G loss: 0.190641]\n","59 [D loss: 0.001602, acc.: 100.00%] [G loss: 0.145149]\n","60 [D loss: 0.001847, acc.: 100.00%] [G loss: 0.155357]\n","61 [D loss: 0.001698, acc.: 100.00%] [G loss: 0.148608]\n","62 [D loss: 0.002382, acc.: 100.00%] [G loss: 0.184049]\n","63 [D loss: 0.003144, acc.: 100.00%] [G loss: 0.134376]\n","64 [D loss: 0.002986, acc.: 100.00%] [G loss: 0.187618]\n","65 [D loss: 0.003590, acc.: 100.00%] [G loss: 0.139401]\n","66 [D loss: 0.003305, acc.: 100.00%] [G loss: 0.136350]\n","67 [D loss: 0.002845, acc.: 100.00%] [G loss: 0.170215]\n","68 [D loss: 0.002092, acc.: 100.00%] [G loss: 0.134203]\n","69 [D loss: 0.001623, acc.: 100.00%] [G loss: 0.151309]\n","70 [D loss: 0.001747, acc.: 100.00%] [G loss: 0.124464]\n","71 [D loss: 0.002143, acc.: 100.00%] [G loss: 0.142568]\n","72 [D loss: 0.002778, acc.: 100.00%] [G loss: 0.130732]\n","73 [D loss: 0.002153, acc.: 100.00%] [G loss: 0.138306]\n","74 [D loss: 0.002082, acc.: 100.00%] [G loss: 0.190413]\n","75 [D loss: 0.003076, acc.: 100.00%] [G loss: 0.119376]\n","76 [D loss: 0.002394, acc.: 100.00%] [G loss: 0.145223]\n","77 [D loss: 0.002320, acc.: 100.00%] [G loss: 0.119722]\n","78 [D loss: 0.003252, acc.: 100.00%] [G loss: 0.113188]\n","79 [D loss: 0.003212, acc.: 100.00%] [G loss: 0.138878]\n","80 [D loss: 0.004949, acc.: 100.00%] [G loss: 0.151600]\n","81 [D loss: 0.004684, acc.: 100.00%] [G loss: 0.133705]\n","82 [D loss: 0.003466, acc.: 100.00%] [G loss: 0.143863]\n","83 [D loss: 0.004335, acc.: 100.00%] [G loss: 0.136656]\n","84 [D loss: 0.002543, acc.: 100.00%] [G loss: 0.152984]\n","85 [D loss: 0.002276, acc.: 100.00%] [G loss: 0.139663]\n","86 [D loss: 0.003920, acc.: 100.00%] [G loss: 0.225425]\n","87 [D loss: 0.005932, acc.: 100.00%] [G loss: 0.190810]\n","88 [D loss: 0.015679, acc.: 100.00%] [G loss: 0.169106]\n","89 [D loss: 0.014425, acc.: 100.00%] [G loss: 0.205769]\n","90 [D loss: 0.014005, acc.: 100.00%] [G loss: 0.357062]\n","91 [D loss: 0.007034, acc.: 100.00%] [G loss: 0.299381]\n","92 [D loss: 0.013358, acc.: 100.00%] [G loss: 0.294388]\n","93 [D loss: 0.007536, acc.: 100.00%] [G loss: 0.471267]\n","94 [D loss: 0.004922, acc.: 100.00%] [G loss: 0.254631]\n","95 [D loss: 0.002818, acc.: 100.00%] [G loss: 0.343184]\n","96 [D loss: 0.001343, acc.: 100.00%] [G loss: 0.254005]\n","97 [D loss: 0.000878, acc.: 100.00%] [G loss: 0.318019]\n","98 [D loss: 0.001811, acc.: 100.00%] [G loss: 0.433547]\n","99 [D loss: 0.006659, acc.: 100.00%] [G loss: 0.298977]\n","100 [D loss: 0.005226, acc.: 100.00%] [G loss: 0.341057]\n","101 [D loss: 0.004393, acc.: 100.00%] [G loss: 0.420646]\n","102 [D loss: 0.002580, acc.: 100.00%] [G loss: 0.323671]\n","103 [D loss: 0.002389, acc.: 100.00%] [G loss: 0.293400]\n","104 [D loss: 0.001509, acc.: 100.00%] [G loss: 0.385011]\n","105 [D loss: 0.004150, acc.: 100.00%] [G loss: 0.226546]\n","106 [D loss: 0.016240, acc.: 100.00%] [G loss: 0.589335]\n","107 [D loss: 0.003679, acc.: 100.00%] [G loss: 0.395135]\n","108 [D loss: 0.002551, acc.: 100.00%] [G loss: 0.397306]\n","109 [D loss: 0.001179, acc.: 100.00%] [G loss: 0.359583]\n","110 [D loss: 0.000690, acc.: 100.00%] [G loss: 0.386256]\n","111 [D loss: 0.002302, acc.: 100.00%] [G loss: 0.305849]\n","112 [D loss: 0.003328, acc.: 100.00%] [G loss: 0.417242]\n","113 [D loss: 0.012407, acc.: 100.00%] [G loss: 0.356536]\n","114 [D loss: 0.002054, acc.: 100.00%] [G loss: 0.286820]\n","115 [D loss: 0.003407, acc.: 100.00%] [G loss: 0.270211]\n","116 [D loss: 0.005975, acc.: 100.00%] [G loss: 0.414051]\n","117 [D loss: 0.007757, acc.: 100.00%] [G loss: 0.372404]\n","118 [D loss: 0.007499, acc.: 100.00%] [G loss: 0.456200]\n","119 [D loss: 0.003119, acc.: 100.00%] [G loss: 0.564317]\n","120 [D loss: 0.002207, acc.: 100.00%] [G loss: 0.631305]\n","121 [D loss: 0.001897, acc.: 100.00%] [G loss: 0.390929]\n","122 [D loss: 0.005975, acc.: 100.00%] [G loss: 0.524975]\n","123 [D loss: 0.004277, acc.: 100.00%] [G loss: 0.575330]\n","124 [D loss: 0.001457, acc.: 100.00%] [G loss: 0.550330]\n","125 [D loss: 0.004660, acc.: 100.00%] [G loss: 0.552683]\n","126 [D loss: 0.011659, acc.: 100.00%] [G loss: 0.394557]\n","127 [D loss: 0.008143, acc.: 100.00%] [G loss: 0.770394]\n","128 [D loss: 0.003492, acc.: 100.00%] [G loss: 0.616730]\n","129 [D loss: 0.001791, acc.: 100.00%] [G loss: 0.579892]\n","130 [D loss: 0.001556, acc.: 100.00%] [G loss: 0.278204]\n","131 [D loss: 0.000847, acc.: 100.00%] [G loss: 0.632939]\n","132 [D loss: 0.000662, acc.: 100.00%] [G loss: 0.527771]\n","133 [D loss: 0.000593, acc.: 100.00%] [G loss: 0.678347]\n","134 [D loss: 0.000275, acc.: 100.00%] [G loss: 0.594225]\n","135 [D loss: 0.000423, acc.: 100.00%] [G loss: 0.408245]\n","136 [D loss: 0.000529, acc.: 100.00%] [G loss: 0.377384]\n","137 [D loss: 0.002482, acc.: 100.00%] [G loss: 0.249036]\n","138 [D loss: 0.002225, acc.: 100.00%] [G loss: 0.296459]\n","139 [D loss: 0.001366, acc.: 100.00%] [G loss: 0.454386]\n","140 [D loss: 0.002154, acc.: 100.00%] [G loss: 0.184621]\n","141 [D loss: 0.002623, acc.: 100.00%] [G loss: 0.239267]\n","142 [D loss: 0.004201, acc.: 100.00%] [G loss: 0.355238]\n","143 [D loss: 0.001678, acc.: 100.00%] [G loss: 0.370453]\n","144 [D loss: 0.001638, acc.: 100.00%] [G loss: 0.213919]\n","145 [D loss: 0.001746, acc.: 100.00%] [G loss: 0.235472]\n","146 [D loss: 0.001375, acc.: 100.00%] [G loss: 0.356381]\n","147 [D loss: 0.002307, acc.: 100.00%] [G loss: 0.326058]\n","148 [D loss: 0.001945, acc.: 100.00%] [G loss: 0.337801]\n","149 [D loss: 0.001151, acc.: 100.00%] [G loss: 0.316562]\n","150 [D loss: 0.001360, acc.: 100.00%] [G loss: 0.254257]\n","151 [D loss: 0.002247, acc.: 100.00%] [G loss: 0.343927]\n","152 [D loss: 0.007975, acc.: 100.00%] [G loss: 0.289502]\n","153 [D loss: 0.003131, acc.: 100.00%] [G loss: 0.318540]\n","154 [D loss: 0.011266, acc.: 100.00%] [G loss: 0.294805]\n","155 [D loss: 0.004509, acc.: 100.00%] [G loss: 0.502492]\n","156 [D loss: 0.001610, acc.: 100.00%] [G loss: 0.555358]\n","157 [D loss: 0.009573, acc.: 100.00%] [G loss: 0.512488]\n","158 [D loss: 0.005994, acc.: 100.00%] [G loss: 0.584138]\n","159 [D loss: 0.004423, acc.: 100.00%] [G loss: 0.597641]\n","160 [D loss: 0.034113, acc.: 100.00%] [G loss: 1.010374]\n","161 [D loss: 0.016793, acc.: 100.00%] [G loss: 1.095191]\n","162 [D loss: 0.005787, acc.: 100.00%] [G loss: 0.989767]\n","163 [D loss: 0.019977, acc.: 100.00%] [G loss: 1.265483]\n","164 [D loss: 0.000533, acc.: 100.00%] [G loss: 1.636787]\n","165 [D loss: 0.001937, acc.: 100.00%] [G loss: 1.614098]\n","166 [D loss: 0.005958, acc.: 100.00%] [G loss: 1.340655]\n","167 [D loss: 0.014542, acc.: 100.00%] [G loss: 1.621324]\n","168 [D loss: 0.003842, acc.: 100.00%] [G loss: 1.543792]\n","169 [D loss: 0.002959, acc.: 100.00%] [G loss: 1.372336]\n","170 [D loss: 0.002452, acc.: 100.00%] [G loss: 1.331779]\n","171 [D loss: 0.001375, acc.: 100.00%] [G loss: 0.781599]\n","172 [D loss: 0.014115, acc.: 100.00%] [G loss: 1.130370]\n","173 [D loss: 0.002034, acc.: 100.00%] [G loss: 1.243050]\n","174 [D loss: 0.005339, acc.: 100.00%] [G loss: 0.902926]\n","175 [D loss: 0.003139, acc.: 100.00%] [G loss: 1.158241]\n","176 [D loss: 0.038356, acc.: 100.00%] [G loss: 1.635919]\n","177 [D loss: 0.024637, acc.: 100.00%] [G loss: 1.097769]\n","178 [D loss: 0.005940, acc.: 100.00%] [G loss: 1.352954]\n","179 [D loss: 0.024764, acc.: 100.00%] [G loss: 1.473005]\n","180 [D loss: 0.001656, acc.: 100.00%] [G loss: 2.226486]\n","181 [D loss: 0.021796, acc.: 100.00%] [G loss: 1.999376]\n","182 [D loss: 0.085357, acc.: 100.00%] [G loss: 2.799971]\n","183 [D loss: 0.670668, acc.: 62.50%] [G loss: 2.588321]\n","184 [D loss: 0.031891, acc.: 100.00%] [G loss: 3.050592]\n","185 [D loss: 0.021748, acc.: 100.00%] [G loss: 2.793777]\n","186 [D loss: 0.010109, acc.: 100.00%] [G loss: 2.679818]\n","187 [D loss: 0.026446, acc.: 100.00%] [G loss: 2.503398]\n","188 [D loss: 0.029696, acc.: 100.00%] [G loss: 2.226455]\n","189 [D loss: 0.019388, acc.: 100.00%] [G loss: 2.511543]\n","190 [D loss: 0.016411, acc.: 100.00%] [G loss: 2.585655]\n","191 [D loss: 0.020020, acc.: 100.00%] [G loss: 2.616934]\n","192 [D loss: 0.023231, acc.: 100.00%] [G loss: 2.520801]\n","193 [D loss: 0.010647, acc.: 100.00%] [G loss: 2.384097]\n","194 [D loss: 0.014203, acc.: 100.00%] [G loss: 2.369413]\n","195 [D loss: 0.023847, acc.: 100.00%] [G loss: 2.547781]\n","196 [D loss: 0.026731, acc.: 100.00%] [G loss: 2.628667]\n","197 [D loss: 0.032842, acc.: 100.00%] [G loss: 2.807439]\n","198 [D loss: 0.010796, acc.: 100.00%] [G loss: 1.990804]\n","199 [D loss: 0.010195, acc.: 100.00%] [G loss: 2.564759]\n","200 [D loss: 0.130927, acc.: 100.00%] [G loss: 2.793580]\n","201 [D loss: 0.230951, acc.: 100.00%] [G loss: 2.196888]\n","202 [D loss: 0.114600, acc.: 100.00%] [G loss: 2.067693]\n","203 [D loss: 0.000129, acc.: 100.00%] [G loss: 2.411994]\n","204 [D loss: 0.000034, acc.: 100.00%] [G loss: 2.099112]\n","205 [D loss: 0.000012, acc.: 100.00%] [G loss: 2.296379]\n","206 [D loss: 0.000033, acc.: 100.00%] [G loss: 1.925600]\n","207 [D loss: 0.000278, acc.: 100.00%] [G loss: 1.435864]\n","208 [D loss: 0.003338, acc.: 100.00%] [G loss: 1.163881]\n","209 [D loss: 0.003392, acc.: 100.00%] [G loss: 1.020878]\n","210 [D loss: 0.007830, acc.: 100.00%] [G loss: 1.176517]\n","211 [D loss: 0.049583, acc.: 100.00%] [G loss: 1.228613]\n","212 [D loss: 0.005238, acc.: 100.00%] [G loss: 1.566415]\n","213 [D loss: 0.004688, acc.: 100.00%] [G loss: 1.107289]\n","214 [D loss: 0.011054, acc.: 100.00%] [G loss: 1.149166]\n","215 [D loss: 0.013397, acc.: 100.00%] [G loss: 1.340541]\n","216 [D loss: 0.036079, acc.: 100.00%] [G loss: 1.068917]\n","217 [D loss: 0.026748, acc.: 100.00%] [G loss: 1.383360]\n","218 [D loss: 0.084767, acc.: 100.00%] [G loss: 1.175527]\n","219 [D loss: 0.040587, acc.: 100.00%] [G loss: 1.466704]\n","220 [D loss: 0.004015, acc.: 100.00%] [G loss: 1.175507]\n","221 [D loss: 0.002829, acc.: 100.00%] [G loss: 1.193665]\n","222 [D loss: 0.025990, acc.: 100.00%] [G loss: 1.057023]\n","223 [D loss: 0.003582, acc.: 100.00%] [G loss: 0.976610]\n","224 [D loss: 0.009293, acc.: 100.00%] [G loss: 1.126258]\n","225 [D loss: 0.010132, acc.: 100.00%] [G loss: 0.991341]\n","226 [D loss: 0.024831, acc.: 100.00%] [G loss: 0.925711]\n","227 [D loss: 0.020538, acc.: 100.00%] [G loss: 0.767433]\n","228 [D loss: 0.244285, acc.: 87.50%] [G loss: 1.464941]\n","229 [D loss: 1.481351, acc.: 25.00%] [G loss: 1.798269]\n","230 [D loss: 0.255126, acc.: 87.50%] [G loss: 2.173618]\n","231 [D loss: 0.000087, acc.: 100.00%] [G loss: 3.567021]\n","232 [D loss: 0.000049, acc.: 100.00%] [G loss: 3.111754]\n","233 [D loss: 0.000177, acc.: 100.00%] [G loss: 3.112526]\n","234 [D loss: 0.000453, acc.: 100.00%] [G loss: 2.889170]\n","235 [D loss: 0.008525, acc.: 100.00%] [G loss: 2.581534]\n","236 [D loss: 0.104045, acc.: 100.00%] [G loss: 2.278683]\n","237 [D loss: 0.028770, acc.: 100.00%] [G loss: 2.394021]\n","238 [D loss: 0.405518, acc.: 93.75%] [G loss: 2.560987]\n","239 [D loss: 0.453987, acc.: 96.88%] [G loss: 3.477976]\n","240 [D loss: 0.065713, acc.: 100.00%] [G loss: 3.195707]\n","241 [D loss: 0.126101, acc.: 100.00%] [G loss: 3.749688]\n","242 [D loss: 0.069455, acc.: 100.00%] [G loss: 3.919165]\n","243 [D loss: 0.096955, acc.: 96.88%] [G loss: 3.996092]\n","244 [D loss: 0.014540, acc.: 100.00%] [G loss: 4.055712]\n","245 [D loss: 0.031121, acc.: 100.00%] [G loss: 3.832442]\n","246 [D loss: 0.014280, acc.: 100.00%] [G loss: 3.597098]\n","247 [D loss: 0.063557, acc.: 100.00%] [G loss: 3.921180]\n","248 [D loss: 0.040459, acc.: 100.00%] [G loss: 3.602468]\n","249 [D loss: 0.032512, acc.: 100.00%] [G loss: 3.690728]\n","250 [D loss: 0.024763, acc.: 100.00%] [G loss: 3.522565]\n","251 [D loss: 0.063950, acc.: 100.00%] [G loss: 3.871379]\n","252 [D loss: 0.034664, acc.: 100.00%] [G loss: 4.784915]\n","253 [D loss: 0.155238, acc.: 96.88%] [G loss: 4.295851]\n","254 [D loss: 0.707146, acc.: 50.00%] [G loss: 5.837975]\n","255 [D loss: 2.099751, acc.: 50.00%] [G loss: 4.874049]\n","256 [D loss: 0.739743, acc.: 62.50%] [G loss: 5.604022]\n","257 [D loss: 0.001275, acc.: 100.00%] [G loss: 6.844417]\n","258 [D loss: 0.092679, acc.: 96.88%] [G loss: 6.506646]\n","259 [D loss: 0.684471, acc.: 65.62%] [G loss: 6.741245]\n","260 [D loss: 0.821764, acc.: 50.00%] [G loss: 5.771354]\n","261 [D loss: 0.151173, acc.: 96.88%] [G loss: 6.580585]\n","262 [D loss: 0.817309, acc.: 56.25%] [G loss: 6.346864]\n","263 [D loss: 1.140245, acc.: 50.00%] [G loss: 5.112923]\n","264 [D loss: 0.264419, acc.: 87.50%] [G loss: 5.493240]\n","265 [D loss: 0.037450, acc.: 100.00%] [G loss: 5.294123]\n","266 [D loss: 0.044434, acc.: 100.00%] [G loss: 5.037392]\n","267 [D loss: 0.067723, acc.: 100.00%] [G loss: 4.503159]\n","268 [D loss: 0.176125, acc.: 100.00%] [G loss: 4.526342]\n","269 [D loss: 0.121742, acc.: 100.00%] [G loss: 4.095469]\n","270 [D loss: 0.228989, acc.: 96.88%] [G loss: 4.129176]\n","271 [D loss: 0.157322, acc.: 100.00%] [G loss: 4.332428]\n","272 [D loss: 0.359606, acc.: 87.50%] [G loss: 4.794476]\n","273 [D loss: 1.443691, acc.: 0.00%] [G loss: 4.271306]\n","274 [D loss: 0.064543, acc.: 100.00%] [G loss: 5.260048]\n","275 [D loss: 0.163458, acc.: 96.88%] [G loss: 4.376902]\n","276 [D loss: 0.186541, acc.: 100.00%] [G loss: 4.388318]\n","277 [D loss: 0.110201, acc.: 100.00%] [G loss: 4.474745]\n","278 [D loss: 0.237686, acc.: 96.88%] [G loss: 4.169509]\n","279 [D loss: 0.361606, acc.: 100.00%] [G loss: 4.094718]\n","280 [D loss: 0.438879, acc.: 78.12%] [G loss: 3.724655]\n","281 [D loss: 0.198941, acc.: 100.00%] [G loss: 3.786145]\n","282 [D loss: 0.097112, acc.: 100.00%] [G loss: 3.996118]\n","283 [D loss: 0.091594, acc.: 100.00%] [G loss: 3.602968]\n","284 [D loss: 0.073429, acc.: 100.00%] [G loss: 3.188224]\n","285 [D loss: 0.099986, acc.: 100.00%] [G loss: 4.220436]\n","286 [D loss: 0.100886, acc.: 100.00%] [G loss: 3.366280]\n","287 [D loss: 0.282112, acc.: 90.62%] [G loss: 3.454870]\n","288 [D loss: 0.238608, acc.: 96.88%] [G loss: 3.100315]\n","289 [D loss: 0.502529, acc.: 56.25%] [G loss: 3.915479]\n","290 [D loss: 0.344803, acc.: 84.38%] [G loss: 3.824693]\n","291 [D loss: 0.826279, acc.: 46.88%] [G loss: 4.024098]\n","292 [D loss: 1.690861, acc.: 0.00%] [G loss: 4.844296]\n","293 [D loss: 1.712487, acc.: 46.88%] [G loss: 3.621588]\n","294 [D loss: 0.911098, acc.: 43.75%] [G loss: 4.698756]\n","295 [D loss: 0.575449, acc.: 65.62%] [G loss: 4.055555]\n","296 [D loss: 0.800330, acc.: 46.88%] [G loss: 4.416057]\n","297 [D loss: 0.541240, acc.: 71.88%] [G loss: 4.181724]\n","298 [D loss: 0.567117, acc.: 78.12%] [G loss: 3.870321]\n","299 [D loss: 0.196824, acc.: 96.88%] [G loss: 4.357291]\n","300 [D loss: 0.272577, acc.: 100.00%] [G loss: 3.465126]\n","301 [D loss: 0.247835, acc.: 96.88%] [G loss: 3.744739]\n","302 [D loss: 0.384474, acc.: 100.00%] [G loss: 3.531851]\n","303 [D loss: 0.224601, acc.: 100.00%] [G loss: 3.668209]\n","304 [D loss: 0.666923, acc.: 46.88%] [G loss: 3.187258]\n","305 [D loss: 0.436206, acc.: 84.38%] [G loss: 3.654261]\n","306 [D loss: 0.702127, acc.: 46.88%] [G loss: 3.215581]\n","307 [D loss: 0.650235, acc.: 62.50%] [G loss: 3.142057]\n","308 [D loss: 0.665682, acc.: 53.12%] [G loss: 3.294590]\n","309 [D loss: 0.548171, acc.: 62.50%] [G loss: 3.257326]\n","310 [D loss: 0.470935, acc.: 100.00%] [G loss: 3.650201]\n","311 [D loss: 0.322110, acc.: 100.00%] [G loss: 3.050840]\n","312 [D loss: 0.522521, acc.: 87.50%] [G loss: 2.951047]\n","313 [D loss: 0.353041, acc.: 100.00%] [G loss: 3.275496]\n","314 [D loss: 0.766408, acc.: 37.50%] [G loss: 3.033255]\n","315 [D loss: 0.998149, acc.: 9.38%] [G loss: 3.092809]\n","316 [D loss: 0.902664, acc.: 40.62%] [G loss: 3.154878]\n","317 [D loss: 0.532313, acc.: 96.88%] [G loss: 2.815310]\n","318 [D loss: 0.585491, acc.: 78.12%] [G loss: 3.038723]\n","319 [D loss: 0.617968, acc.: 78.12%] [G loss: 3.044688]\n","320 [D loss: 0.713455, acc.: 46.88%] [G loss: 2.783769]\n","321 [D loss: 0.761220, acc.: 46.88%] [G loss: 2.804316]\n","322 [D loss: 1.038379, acc.: 3.12%] [G loss: 2.583099]\n","323 [D loss: 0.980661, acc.: 18.75%] [G loss: 2.321583]\n","324 [D loss: 1.127783, acc.: 0.00%] [G loss: 1.895313]\n","325 [D loss: 1.068059, acc.: 0.00%] [G loss: 2.669592]\n","326 [D loss: 1.131965, acc.: 0.00%] [G loss: 2.090997]\n","327 [D loss: 1.395081, acc.: 0.00%] [G loss: 2.328857]\n","328 [D loss: 1.382297, acc.: 0.00%] [G loss: 1.878218]\n","329 [D loss: 1.275866, acc.: 0.00%] [G loss: 2.058547]\n","330 [D loss: 0.939923, acc.: 12.50%] [G loss: 2.166490]\n","331 [D loss: 1.130896, acc.: 0.00%] [G loss: 2.316938]\n","332 [D loss: 1.153019, acc.: 3.12%] [G loss: 2.138402]\n","333 [D loss: 1.209886, acc.: 0.00%] [G loss: 2.267107]\n","334 [D loss: 1.128573, acc.: 0.00%] [G loss: 2.467960]\n","335 [D loss: 1.050667, acc.: 0.00%] [G loss: 1.981781]\n","336 [D loss: 1.007560, acc.: 12.50%] [G loss: 2.077033]\n","337 [D loss: 0.822677, acc.: 31.25%] [G loss: 1.978415]\n","338 [D loss: 0.646706, acc.: 68.75%] [G loss: 2.175663]\n","339 [D loss: 0.567862, acc.: 78.12%] [G loss: 2.331351]\n","340 [D loss: 0.605671, acc.: 65.62%] [G loss: 2.475676]\n","341 [D loss: 0.706108, acc.: 50.00%] [G loss: 2.151829]\n","342 [D loss: 0.763426, acc.: 40.62%] [G loss: 2.226089]\n","343 [D loss: 0.837803, acc.: 50.00%] [G loss: 2.115519]\n","344 [D loss: 0.788793, acc.: 25.00%] [G loss: 1.831486]\n","345 [D loss: 0.372444, acc.: 90.62%] [G loss: 1.958831]\n","346 [D loss: 0.633928, acc.: 71.88%] [G loss: 1.820901]\n","347 [D loss: 0.640374, acc.: 62.50%] [G loss: 1.763355]\n","348 [D loss: 0.730230, acc.: 59.38%] [G loss: 2.202116]\n","349 [D loss: 0.844363, acc.: 9.38%] [G loss: 1.958992]\n","350 [D loss: 0.878296, acc.: 3.12%] [G loss: 1.787680]\n","351 [D loss: 0.899884, acc.: 0.00%] [G loss: 1.637118]\n","352 [D loss: 1.066021, acc.: 0.00%] [G loss: 1.606244]\n","353 [D loss: 0.793704, acc.: 25.00%] [G loss: 1.492275]\n","354 [D loss: 0.700378, acc.: 56.25%] [G loss: 1.464747]\n","355 [D loss: 0.899072, acc.: 6.25%] [G loss: 1.590949]\n","356 [D loss: 0.754509, acc.: 50.00%] [G loss: 1.589627]\n","357 [D loss: 0.805448, acc.: 34.38%] [G loss: 1.391131]\n","358 [D loss: 0.669483, acc.: 53.12%] [G loss: 1.529288]\n","359 [D loss: 0.858623, acc.: 25.00%] [G loss: 1.290027]\n","360 [D loss: 0.830623, acc.: 50.00%] [G loss: 1.344739]\n","361 [D loss: 1.111722, acc.: 0.00%] [G loss: 1.136592]\n","362 [D loss: 0.919429, acc.: 46.88%] [G loss: 0.938268]\n","363 [D loss: 1.008390, acc.: 6.25%] [G loss: 1.057194]\n","364 [D loss: 0.948083, acc.: 0.00%] [G loss: 1.245918]\n","365 [D loss: 0.943577, acc.: 0.00%] [G loss: 1.205018]\n","366 [D loss: 0.930322, acc.: 50.00%] [G loss: 1.076436]\n","367 [D loss: 0.983965, acc.: 3.12%] [G loss: 1.193139]\n","368 [D loss: 0.814858, acc.: 31.25%] [G loss: 1.065534]\n","369 [D loss: 0.785436, acc.: 50.00%] [G loss: 1.205151]\n","370 [D loss: 0.838638, acc.: 9.38%] [G loss: 1.041799]\n","371 [D loss: 0.740808, acc.: 46.88%] [G loss: 0.994895]\n","372 [D loss: 0.806227, acc.: 59.38%] [G loss: 0.846101]\n","373 [D loss: 0.802711, acc.: 15.62%] [G loss: 0.830035]\n","374 [D loss: 0.743911, acc.: 62.50%] [G loss: 0.860205]\n","375 [D loss: 0.871585, acc.: 9.38%] [G loss: 0.732178]\n","376 [D loss: 0.761328, acc.: 59.38%] [G loss: 0.843164]\n","377 [D loss: 0.894195, acc.: 59.38%] [G loss: 0.809180]\n","378 [D loss: 0.681285, acc.: 75.00%] [G loss: 0.899379]\n","379 [D loss: 0.717969, acc.: 62.50%] [G loss: 0.625502]\n","380 [D loss: 0.760778, acc.: 65.62%] [G loss: 0.721680]\n","381 [D loss: 0.775421, acc.: 43.75%] [G loss: 0.716489]\n","382 [D loss: 0.724214, acc.: 68.75%] [G loss: 1.012759]\n","383 [D loss: 0.840615, acc.: 62.50%] [G loss: 0.792182]\n","384 [D loss: 0.776306, acc.: 31.25%] [G loss: 0.730078]\n","385 [D loss: 0.804757, acc.: 68.75%] [G loss: 0.778014]\n","386 [D loss: 0.707213, acc.: 78.12%] [G loss: 0.906558]\n","387 [D loss: 0.739183, acc.: 71.88%] [G loss: 0.640709]\n","388 [D loss: 0.708893, acc.: 59.38%] [G loss: 0.693032]\n","389 [D loss: 0.645923, acc.: 78.12%] [G loss: 0.556803]\n","390 [D loss: 0.812095, acc.: 75.00%] [G loss: 0.765896]\n","391 [D loss: 0.723052, acc.: 59.38%] [G loss: 0.716940]\n","392 [D loss: 0.590584, acc.: 81.25%] [G loss: 0.743159]\n","393 [D loss: 0.814817, acc.: 71.88%] [G loss: 0.694067]\n","394 [D loss: 0.869304, acc.: 28.12%] [G loss: 0.852336]\n","395 [D loss: 0.781731, acc.: 78.12%] [G loss: 0.996907]\n","396 [D loss: 1.015424, acc.: 25.00%] [G loss: 0.845470]\n","397 [D loss: 1.062978, acc.: 18.75%] [G loss: 0.751667]\n","398 [D loss: 0.784501, acc.: 46.88%] [G loss: 0.827910]\n","399 [D loss: 0.786891, acc.: 71.88%] [G loss: 0.910355]\n","400 [D loss: 0.705217, acc.: 84.38%] [G loss: 0.906635]\n","401 [D loss: 0.929064, acc.: 21.88%] [G loss: 0.690498]\n","402 [D loss: 0.746786, acc.: 68.75%] [G loss: 0.835034]\n","403 [D loss: 0.441359, acc.: 90.62%] [G loss: 0.750944]\n","404 [D loss: 0.868962, acc.: 28.12%] [G loss: 0.776106]\n","405 [D loss: 0.952699, acc.: 28.12%] [G loss: 0.893821]\n","406 [D loss: 0.778826, acc.: 62.50%] [G loss: 0.876401]\n","407 [D loss: 1.073232, acc.: 53.12%] [G loss: 0.883435]\n","408 [D loss: 0.875220, acc.: 21.88%] [G loss: 0.861799]\n","409 [D loss: 1.002496, acc.: 21.88%] [G loss: 0.708721]\n","410 [D loss: 1.008541, acc.: 18.75%] [G loss: 0.914121]\n","411 [D loss: 0.835003, acc.: 62.50%] [G loss: 0.820514]\n","412 [D loss: 0.813209, acc.: 40.62%] [G loss: 0.697551]\n","413 [D loss: 0.737491, acc.: 71.88%] [G loss: 0.732479]\n","414 [D loss: 0.838173, acc.: 46.88%] [G loss: 0.815329]\n","415 [D loss: 0.695987, acc.: 68.75%] [G loss: 0.702319]\n","416 [D loss: 0.952025, acc.: 15.62%] [G loss: 0.703488]\n","417 [D loss: 0.736467, acc.: 71.88%] [G loss: 0.827752]\n","418 [D loss: 0.937686, acc.: 9.38%] [G loss: 0.680532]\n","419 [D loss: 0.861053, acc.: 15.62%] [G loss: 0.673548]\n","420 [D loss: 1.115245, acc.: 0.00%] [G loss: 0.983839]\n","421 [D loss: 1.060702, acc.: 3.12%] [G loss: 0.702071]\n","422 [D loss: 1.212899, acc.: 0.00%] [G loss: 0.950832]\n","423 [D loss: 1.380164, acc.: 0.00%] [G loss: 0.628901]\n","424 [D loss: 1.318976, acc.: 0.00%] [G loss: 0.781454]\n","425 [D loss: 1.277764, acc.: 3.12%] [G loss: 0.579992]\n","426 [D loss: 1.191656, acc.: 0.00%] [G loss: 0.585725]\n","427 [D loss: 1.449737, acc.: 0.00%] [G loss: 0.847494]\n","428 [D loss: 1.353998, acc.: 0.00%] [G loss: 0.570949]\n","429 [D loss: 1.166250, acc.: 0.00%] [G loss: 0.675161]\n","430 [D loss: 1.117199, acc.: 0.00%] [G loss: 0.590578]\n","431 [D loss: 0.963777, acc.: 0.00%] [G loss: 0.703432]\n","432 [D loss: 0.967213, acc.: 0.00%] [G loss: 0.602335]\n","433 [D loss: 0.953752, acc.: 0.00%] [G loss: 0.733880]\n","434 [D loss: 0.915282, acc.: 0.00%] [G loss: 0.587633]\n","435 [D loss: 0.804078, acc.: 50.00%] [G loss: 0.580810]\n","436 [D loss: 0.893325, acc.: 50.00%] [G loss: 0.517523]\n","437 [D loss: 0.881943, acc.: 0.00%] [G loss: 0.610051]\n","438 [D loss: 0.831591, acc.: 0.00%] [G loss: 0.574109]\n","439 [D loss: 0.848630, acc.: 50.00%] [G loss: 0.587191]\n","440 [D loss: 0.914482, acc.: 0.00%] [G loss: 0.489947]\n","441 [D loss: 0.832879, acc.: 40.62%] [G loss: 0.567285]\n","442 [D loss: 0.781974, acc.: 50.00%] [G loss: 0.466422]\n","443 [D loss: 0.739333, acc.: 31.25%] [G loss: 0.575047]\n","444 [D loss: 0.674802, acc.: 53.12%] [G loss: 0.490303]\n","445 [D loss: 0.635321, acc.: 71.88%] [G loss: 0.651828]\n","446 [D loss: 0.644219, acc.: 71.88%] [G loss: 0.385339]\n","447 [D loss: 0.702695, acc.: 62.50%] [G loss: 0.484149]\n","448 [D loss: 0.648868, acc.: 65.62%] [G loss: 0.493103]\n","449 [D loss: 0.657862, acc.: 56.25%] [G loss: 0.502120]\n","450 [D loss: 0.693155, acc.: 56.25%] [G loss: 0.455707]\n","451 [D loss: 0.624599, acc.: 78.12%] [G loss: 0.505882]\n","452 [D loss: 0.606157, acc.: 75.00%] [G loss: 0.403510]\n","453 [D loss: 0.639803, acc.: 71.88%] [G loss: 0.536605]\n","454 [D loss: 0.693111, acc.: 71.88%] [G loss: 0.437693]\n","455 [D loss: 0.605734, acc.: 84.38%] [G loss: 0.588851]\n","456 [D loss: 0.663128, acc.: 59.38%] [G loss: 0.458628]\n","457 [D loss: 0.627679, acc.: 78.12%] [G loss: 0.474594]\n","458 [D loss: 0.628819, acc.: 78.12%] [G loss: 0.532860]\n","459 [D loss: 0.645524, acc.: 75.00%] [G loss: 0.506117]\n","460 [D loss: 0.663293, acc.: 75.00%] [G loss: 0.503851]\n","461 [D loss: 0.654814, acc.: 68.75%] [G loss: 0.446584]\n","462 [D loss: 0.618863, acc.: 75.00%] [G loss: 0.623129]\n","463 [D loss: 0.628586, acc.: 75.00%] [G loss: 0.416726]\n","464 [D loss: 0.721385, acc.: 34.38%] [G loss: 0.502179]\n","465 [D loss: 0.675624, acc.: 68.75%] [G loss: 0.608437]\n","466 [D loss: 0.744182, acc.: 71.88%] [G loss: 0.498313]\n","467 [D loss: 0.694693, acc.: 65.62%] [G loss: 0.413968]\n","468 [D loss: 0.677448, acc.: 71.88%] [G loss: 0.546675]\n","469 [D loss: 0.847976, acc.: 40.62%] [G loss: 0.512516]\n","470 [D loss: 0.767010, acc.: 59.38%] [G loss: 0.543562]\n","471 [D loss: 0.779179, acc.: 28.12%] [G loss: 0.517680]\n","472 [D loss: 0.844260, acc.: 15.62%] [G loss: 0.544394]\n","473 [D loss: 0.925897, acc.: 43.75%] [G loss: 0.543007]\n","474 [D loss: 0.932823, acc.: 0.00%] [G loss: 0.542619]\n","475 [D loss: 0.884817, acc.: 0.00%] [G loss: 0.529739]\n","476 [D loss: 1.035415, acc.: 0.00%] [G loss: 0.535474]\n","477 [D loss: 0.984642, acc.: 0.00%] [G loss: 0.457626]\n","478 [D loss: 1.120191, acc.: 0.00%] [G loss: 0.437396]\n","479 [D loss: 0.913792, acc.: 0.00%] [G loss: 0.388310]\n","480 [D loss: 1.040432, acc.: 46.88%] [G loss: 0.499310]\n","481 [D loss: 0.909603, acc.: 0.00%] [G loss: 0.418628]\n","482 [D loss: 0.924789, acc.: 9.38%] [G loss: 0.384030]\n","483 [D loss: 0.807868, acc.: 62.50%] [G loss: 0.457383]\n","484 [D loss: 0.859057, acc.: 56.25%] [G loss: 0.376146]\n","485 [D loss: 0.796990, acc.: 62.50%] [G loss: 0.364940]\n","486 [D loss: 0.836247, acc.: 40.62%] [G loss: 0.384949]\n","487 [D loss: 0.722906, acc.: 75.00%] [G loss: 0.410448]\n","488 [D loss: 0.855611, acc.: 59.38%] [G loss: 0.388895]\n","489 [D loss: 0.910844, acc.: 18.75%] [G loss: 0.311371]\n","490 [D loss: 0.915778, acc.: 6.25%] [G loss: 0.341072]\n","491 [D loss: 0.816729, acc.: 18.75%] [G loss: 0.374765]\n","492 [D loss: 0.983205, acc.: 12.50%] [G loss: 0.476508]\n","493 [D loss: 0.784777, acc.: 65.62%] [G loss: 0.378991]\n","494 [D loss: 0.902653, acc.: 53.12%] [G loss: 0.378586]\n","495 [D loss: 0.932569, acc.: 12.50%] [G loss: 0.284373]\n","496 [D loss: 0.718533, acc.: 68.75%] [G loss: 0.440263]\n","497 [D loss: 0.736388, acc.: 65.62%] [G loss: 0.337048]\n","498 [D loss: 0.814988, acc.: 56.25%] [G loss: 0.323220]\n","499 [D loss: 0.724487, acc.: 50.00%] [G loss: 0.334844]\n","500 [D loss: 0.624377, acc.: 75.00%] [G loss: 0.483621]\n","501 [D loss: 0.737297, acc.: 68.75%] [G loss: 0.312804]\n","502 [D loss: 0.699850, acc.: 62.50%] [G loss: 0.337249]\n","503 [D loss: 0.653474, acc.: 75.00%] [G loss: 0.436867]\n","504 [D loss: 0.535043, acc.: 81.25%] [G loss: 0.320281]\n","505 [D loss: 0.580474, acc.: 75.00%] [G loss: 0.321151]\n","506 [D loss: 0.578849, acc.: 75.00%] [G loss: 0.383672]\n","507 [D loss: 0.633011, acc.: 68.75%] [G loss: 0.298805]\n","508 [D loss: 0.656628, acc.: 65.62%] [G loss: 0.403394]\n","509 [D loss: 0.615755, acc.: 78.12%] [G loss: 0.365072]\n","510 [D loss: 0.707524, acc.: 65.62%] [G loss: 0.375094]\n","511 [D loss: 0.639927, acc.: 78.12%] [G loss: 0.399875]\n","512 [D loss: 0.731543, acc.: 59.38%] [G loss: 0.411218]\n","513 [D loss: 0.678851, acc.: 65.62%] [G loss: 0.370170]\n","514 [D loss: 0.688943, acc.: 62.50%] [G loss: 0.320723]\n","515 [D loss: 0.815211, acc.: 56.25%] [G loss: 0.373603]\n","516 [D loss: 0.801224, acc.: 9.38%] [G loss: 0.384624]\n","517 [D loss: 0.729188, acc.: 53.12%] [G loss: 0.373944]\n","518 [D loss: 0.815218, acc.: 56.25%] [G loss: 0.332604]\n","519 [D loss: 0.857063, acc.: 34.38%] [G loss: 0.278441]\n","520 [D loss: 0.826603, acc.: 15.62%] [G loss: 0.320686]\n","521 [D loss: 0.878943, acc.: 21.88%] [G loss: 0.412611]\n","522 [D loss: 0.974421, acc.: 15.62%] [G loss: 0.280429]\n","523 [D loss: 1.060157, acc.: 3.12%] [G loss: 0.316449]\n","524 [D loss: 1.003653, acc.: 3.12%] [G loss: 0.362571]\n","525 [D loss: 0.860986, acc.: 53.12%] [G loss: 0.508353]\n","526 [D loss: 0.746596, acc.: 65.62%] [G loss: 0.478974]\n","527 [D loss: 0.770580, acc.: 59.38%] [G loss: 0.315559]\n","528 [D loss: 0.849758, acc.: 25.00%] [G loss: 0.330426]\n","529 [D loss: 0.791319, acc.: 50.00%] [G loss: 0.379430]\n","530 [D loss: 0.828037, acc.: 65.62%] [G loss: 0.479346]\n","531 [D loss: 0.745141, acc.: 65.62%] [G loss: 0.432980]\n","532 [D loss: 0.838886, acc.: 15.62%] [G loss: 0.383059]\n","533 [D loss: 0.818015, acc.: 25.00%] [G loss: 0.590203]\n","534 [D loss: 0.874955, acc.: 37.50%] [G loss: 0.507283]\n","535 [D loss: 0.913958, acc.: 50.00%] [G loss: 0.430231]\n","536 [D loss: 0.863862, acc.: 12.50%] [G loss: 0.442367]\n","537 [D loss: 0.774398, acc.: 56.25%] [G loss: 0.414607]\n","538 [D loss: 0.841856, acc.: 28.12%] [G loss: 0.448601]\n","539 [D loss: 0.818133, acc.: 46.88%] [G loss: 0.447315]\n","540 [D loss: 0.863248, acc.: 56.25%] [G loss: 0.406662]\n","541 [D loss: 0.868901, acc.: 3.12%] [G loss: 0.484591]\n","542 [D loss: 0.868212, acc.: 3.12%] [G loss: 0.441642]\n","543 [D loss: 0.916606, acc.: 12.50%] [G loss: 0.430326]\n","544 [D loss: 0.794465, acc.: 56.25%] [G loss: 0.419836]\n","545 [D loss: 0.955734, acc.: 3.12%] [G loss: 0.482370]\n","546 [D loss: 0.910667, acc.: 3.12%] [G loss: 0.376201]\n","547 [D loss: 0.874529, acc.: 6.25%] [G loss: 0.388982]\n","548 [D loss: 0.792267, acc.: 37.50%] [G loss: 0.451775]\n","549 [D loss: 0.942302, acc.: 0.00%] [G loss: 0.462529]\n","550 [D loss: 0.852541, acc.: 3.12%] [G loss: 0.521000]\n","551 [D loss: 0.873345, acc.: 9.38%] [G loss: 0.499855]\n","552 [D loss: 0.827563, acc.: 28.12%] [G loss: 0.525015]\n","553 [D loss: 0.855333, acc.: 37.50%] [G loss: 0.511268]\n","554 [D loss: 1.014097, acc.: 0.00%] [G loss: 0.604810]\n","555 [D loss: 0.939300, acc.: 0.00%] [G loss: 0.425276]\n","556 [D loss: 0.904256, acc.: 0.00%] [G loss: 0.507092]\n","557 [D loss: 1.022736, acc.: 0.00%] [G loss: 0.533484]\n","558 [D loss: 1.001640, acc.: 6.25%] [G loss: 0.547695]\n","559 [D loss: 0.962197, acc.: 0.00%] [G loss: 0.689418]\n","560 [D loss: 1.063012, acc.: 0.00%] [G loss: 0.594349]\n","561 [D loss: 1.201475, acc.: 0.00%] [G loss: 0.532206]\n","562 [D loss: 1.150524, acc.: 3.12%] [G loss: 0.571098]\n","563 [D loss: 1.152125, acc.: 0.00%] [G loss: 0.519471]\n","564 [D loss: 1.102807, acc.: 0.00%] [G loss: 0.615985]\n","565 [D loss: 0.995021, acc.: 0.00%] [G loss: 0.601139]\n","566 [D loss: 1.016402, acc.: 0.00%] [G loss: 0.551277]\n","567 [D loss: 0.993675, acc.: 0.00%] [G loss: 0.596671]\n","568 [D loss: 0.932910, acc.: 0.00%] [G loss: 0.561774]\n","569 [D loss: 0.965304, acc.: 0.00%] [G loss: 0.573519]\n","570 [D loss: 0.984496, acc.: 0.00%] [G loss: 0.532878]\n","571 [D loss: 0.919428, acc.: 0.00%] [G loss: 0.534095]\n","572 [D loss: 0.893856, acc.: 0.00%] [G loss: 0.577784]\n","573 [D loss: 0.858979, acc.: 0.00%] [G loss: 0.541470]\n","574 [D loss: 0.908022, acc.: 0.00%] [G loss: 0.603563]\n","575 [D loss: 0.873778, acc.: 0.00%] [G loss: 0.546841]\n","576 [D loss: 0.896909, acc.: 0.00%] [G loss: 0.531743]\n","577 [D loss: 0.842632, acc.: 9.38%] [G loss: 0.536060]\n","578 [D loss: 0.857861, acc.: 0.00%] [G loss: 0.569968]\n","579 [D loss: 0.758905, acc.: 50.00%] [G loss: 0.605817]\n","580 [D loss: 0.775507, acc.: 50.00%] [G loss: 0.503577]\n","581 [D loss: 0.771363, acc.: 50.00%] [G loss: 0.529161]\n","582 [D loss: 0.694644, acc.: 81.25%] [G loss: 0.572615]\n","583 [D loss: 0.698569, acc.: 71.88%] [G loss: 0.468397]\n","584 [D loss: 0.700734, acc.: 62.50%] [G loss: 0.700634]\n","585 [D loss: 0.717787, acc.: 65.62%] [G loss: 0.534289]\n","586 [D loss: 0.746459, acc.: 65.62%] [G loss: 0.520177]\n","587 [D loss: 0.727631, acc.: 71.88%] [G loss: 0.594735]\n","588 [D loss: 0.647681, acc.: 68.75%] [G loss: 0.542154]\n","589 [D loss: 0.657146, acc.: 68.75%] [G loss: 0.547220]\n","590 [D loss: 0.699409, acc.: 68.75%] [G loss: 0.560479]\n","591 [D loss: 0.645736, acc.: 71.88%] [G loss: 0.585076]\n","592 [D loss: 0.605240, acc.: 90.62%] [G loss: 0.574602]\n","593 [D loss: 0.692516, acc.: 75.00%] [G loss: 0.562931]\n","594 [D loss: 0.817039, acc.: 21.88%] [G loss: 0.551544]\n","595 [D loss: 0.688430, acc.: 81.25%] [G loss: 0.626044]\n","596 [D loss: 0.645557, acc.: 71.88%] [G loss: 0.648839]\n","597 [D loss: 0.679748, acc.: 68.75%] [G loss: 0.593144]\n","598 [D loss: 0.676771, acc.: 68.75%] [G loss: 0.536063]\n","599 [D loss: 0.693808, acc.: 71.88%] [G loss: 0.675793]\n","600 [D loss: 0.679832, acc.: 75.00%] [G loss: 0.561425]\n","601 [D loss: 0.721042, acc.: 68.75%] [G loss: 0.674573]\n","602 [D loss: 0.768773, acc.: 65.62%] [G loss: 0.590285]\n","603 [D loss: 0.714120, acc.: 81.25%] [G loss: 0.631083]\n","604 [D loss: 0.802991, acc.: 59.38%] [G loss: 0.643186]\n","605 [D loss: 0.716181, acc.: 75.00%] [G loss: 0.611143]\n","606 [D loss: 0.773875, acc.: 53.12%] [G loss: 0.582524]\n","607 [D loss: 0.761425, acc.: 62.50%] [G loss: 0.665006]\n","608 [D loss: 0.757539, acc.: 56.25%] [G loss: 0.628138]\n","609 [D loss: 0.796683, acc.: 53.12%] [G loss: 0.590237]\n","610 [D loss: 0.775924, acc.: 56.25%] [G loss: 0.601903]\n","611 [D loss: 0.669815, acc.: 65.62%] [G loss: 0.644536]\n","612 [D loss: 0.665251, acc.: 71.88%] [G loss: 0.607544]\n","613 [D loss: 0.751681, acc.: 53.12%] [G loss: 0.612198]\n","614 [D loss: 0.782726, acc.: 12.50%] [G loss: 0.606114]\n","615 [D loss: 0.764264, acc.: 53.12%] [G loss: 0.583677]\n","616 [D loss: 0.676346, acc.: 53.12%] [G loss: 0.629077]\n","617 [D loss: 0.704496, acc.: 56.25%] [G loss: 0.535146]\n","618 [D loss: 0.735806, acc.: 50.00%] [G loss: 0.547771]\n","619 [D loss: 0.702627, acc.: 78.12%] [G loss: 0.594343]\n","620 [D loss: 0.701057, acc.: 50.00%] [G loss: 0.558320]\n","621 [D loss: 0.765744, acc.: 50.00%] [G loss: 0.565945]\n","622 [D loss: 0.787971, acc.: 50.00%] [G loss: 0.491303]\n","623 [D loss: 0.753300, acc.: 59.38%] [G loss: 0.602846]\n","624 [D loss: 0.738344, acc.: 56.25%] [G loss: 0.670886]\n","625 [D loss: 0.740886, acc.: 50.00%] [G loss: 0.468899]\n","626 [D loss: 0.802727, acc.: 50.00%] [G loss: 0.580144]\n","627 [D loss: 0.812065, acc.: 18.75%] [G loss: 0.595228]\n","628 [D loss: 0.829268, acc.: 6.25%] [G loss: 0.494664]\n","629 [D loss: 0.903626, acc.: 0.00%] [G loss: 0.461960]\n","630 [D loss: 0.941908, acc.: 0.00%] [G loss: 0.561493]\n","631 [D loss: 0.938429, acc.: 0.00%] [G loss: 0.489764]\n","632 [D loss: 0.865861, acc.: 3.12%] [G loss: 0.521163]\n","633 [D loss: 0.788543, acc.: 50.00%] [G loss: 0.540491]\n","634 [D loss: 0.782746, acc.: 46.88%] [G loss: 0.631321]\n","635 [D loss: 0.794842, acc.: 59.38%] [G loss: 0.485112]\n","636 [D loss: 0.821619, acc.: 12.50%] [G loss: 0.539660]\n","637 [D loss: 0.756338, acc.: 31.25%] [G loss: 0.521662]\n","638 [D loss: 0.661025, acc.: 68.75%] [G loss: 0.647843]\n","639 [D loss: 0.728928, acc.: 65.62%] [G loss: 0.591596]\n","640 [D loss: 0.602706, acc.: 75.00%] [G loss: 0.597077]\n","641 [D loss: 0.663815, acc.: 75.00%] [G loss: 0.588886]\n","642 [D loss: 0.627157, acc.: 71.88%] [G loss: 0.504580]\n","643 [D loss: 0.716441, acc.: 28.12%] [G loss: 0.736983]\n","644 [D loss: 0.658806, acc.: 75.00%] [G loss: 0.613287]\n","645 [D loss: 0.618395, acc.: 75.00%] [G loss: 0.629610]\n","646 [D loss: 0.798939, acc.: 21.88%] [G loss: 0.647228]\n","647 [D loss: 0.679807, acc.: 78.12%] [G loss: 0.545287]\n","648 [D loss: 0.796013, acc.: 56.25%] [G loss: 0.605696]\n","649 [D loss: 0.751924, acc.: 62.50%] [G loss: 0.559709]\n","650 [D loss: 0.773490, acc.: 25.00%] [G loss: 0.549033]\n","651 [D loss: 0.707712, acc.: 65.62%] [G loss: 0.580507]\n","652 [D loss: 0.730037, acc.: 68.75%] [G loss: 0.523520]\n","653 [D loss: 0.572563, acc.: 81.25%] [G loss: 0.550709]\n","654 [D loss: 0.674449, acc.: 68.75%] [G loss: 0.513504]\n","655 [D loss: 0.647125, acc.: 81.25%] [G loss: 0.543877]\n","656 [D loss: 0.698759, acc.: 75.00%] [G loss: 0.551247]\n","657 [D loss: 0.805098, acc.: 56.25%] [G loss: 0.504014]\n","658 [D loss: 0.792291, acc.: 56.25%] [G loss: 0.505096]\n","659 [D loss: 0.963625, acc.: 6.25%] [G loss: 0.673841]\n","660 [D loss: 0.855482, acc.: 12.50%] [G loss: 0.544346]\n","661 [D loss: 0.882353, acc.: 31.25%] [G loss: 0.615759]\n","662 [D loss: 0.857665, acc.: 6.25%] [G loss: 0.580102]\n","663 [D loss: 0.964053, acc.: 25.00%] [G loss: 0.507968]\n","664 [D loss: 0.950564, acc.: 15.62%] [G loss: 0.474083]\n","665 [D loss: 0.845826, acc.: 9.38%] [G loss: 0.482798]\n","666 [D loss: 0.976786, acc.: 0.00%] [G loss: 0.513430]\n","667 [D loss: 0.891948, acc.: 0.00%] [G loss: 0.469731]\n","668 [D loss: 0.836277, acc.: 28.12%] [G loss: 0.487615]\n","669 [D loss: 0.890576, acc.: 31.25%] [G loss: 0.515380]\n","670 [D loss: 0.927156, acc.: 0.00%] [G loss: 0.536313]\n","671 [D loss: 0.877651, acc.: 0.00%] [G loss: 0.480624]\n","672 [D loss: 0.886005, acc.: 0.00%] [G loss: 0.496430]\n","673 [D loss: 0.825483, acc.: 34.38%] [G loss: 0.500858]\n","674 [D loss: 0.846538, acc.: 46.88%] [G loss: 0.573768]\n","675 [D loss: 0.832404, acc.: 40.62%] [G loss: 0.489032]\n","676 [D loss: 0.828929, acc.: 37.50%] [G loss: 0.488578]\n","677 [D loss: 0.812720, acc.: 31.25%] [G loss: 0.498132]\n","678 [D loss: 0.824544, acc.: 37.50%] [G loss: 0.457642]\n","679 [D loss: 0.840461, acc.: 9.38%] [G loss: 0.520042]\n","680 [D loss: 0.805746, acc.: 31.25%] [G loss: 0.453200]\n","681 [D loss: 0.757808, acc.: 50.00%] [G loss: 0.591995]\n","682 [D loss: 0.756512, acc.: 50.00%] [G loss: 0.551263]\n","683 [D loss: 0.749905, acc.: 50.00%] [G loss: 0.549092]\n","684 [D loss: 0.720797, acc.: 50.00%] [G loss: 0.432947]\n","685 [D loss: 0.694562, acc.: 53.12%] [G loss: 0.471932]\n","686 [D loss: 0.710830, acc.: 50.00%] [G loss: 0.393276]\n","687 [D loss: 0.735259, acc.: 43.75%] [G loss: 0.417457]\n","688 [D loss: 0.833528, acc.: 6.25%] [G loss: 0.480637]\n","689 [D loss: 0.883646, acc.: 0.00%] [G loss: 0.495676]\n","690 [D loss: 0.735680, acc.: 50.00%] [G loss: 0.509433]\n","691 [D loss: 0.759003, acc.: 50.00%] [G loss: 0.477709]\n","692 [D loss: 0.822714, acc.: 3.12%] [G loss: 0.486375]\n","693 [D loss: 0.860183, acc.: 12.50%] [G loss: 0.445275]\n","694 [D loss: 0.739879, acc.: 59.38%] [G loss: 0.568431]\n","695 [D loss: 0.686851, acc.: 53.12%] [G loss: 0.476627]\n","696 [D loss: 0.662390, acc.: 59.38%] [G loss: 0.459650]\n","697 [D loss: 0.671150, acc.: 68.75%] [G loss: 0.513251]\n","698 [D loss: 0.697851, acc.: 59.38%] [G loss: 0.484444]\n","699 [D loss: 0.659835, acc.: 71.88%] [G loss: 0.499924]\n","700 [D loss: 0.637173, acc.: 75.00%] [G loss: 0.424514]\n","701 [D loss: 0.682756, acc.: 68.75%] [G loss: 0.453119]\n","702 [D loss: 0.663099, acc.: 59.38%] [G loss: 0.536056]\n","703 [D loss: 0.669811, acc.: 62.50%] [G loss: 0.423613]\n","704 [D loss: 0.660003, acc.: 59.38%] [G loss: 0.536653]\n","705 [D loss: 0.642155, acc.: 75.00%] [G loss: 0.491529]\n","706 [D loss: 0.640250, acc.: 75.00%] [G loss: 0.500655]\n","707 [D loss: 0.639911, acc.: 75.00%] [G loss: 0.603469]\n","708 [D loss: 0.643716, acc.: 71.88%] [G loss: 0.535471]\n","709 [D loss: 0.673420, acc.: 68.75%] [G loss: 0.498730]\n","710 [D loss: 0.677185, acc.: 68.75%] [G loss: 0.546248]\n","711 [D loss: 0.678177, acc.: 75.00%] [G loss: 0.546963]\n","712 [D loss: 0.627212, acc.: 71.88%] [G loss: 0.476297]\n","713 [D loss: 0.692223, acc.: 59.38%] [G loss: 0.597993]\n","714 [D loss: 0.696507, acc.: 62.50%] [G loss: 0.541512]\n","715 [D loss: 0.687024, acc.: 68.75%] [G loss: 0.540130]\n","716 [D loss: 0.678180, acc.: 68.75%] [G loss: 0.526445]\n","717 [D loss: 0.616212, acc.: 65.62%] [G loss: 0.522854]\n","718 [D loss: 0.686775, acc.: 68.75%] [G loss: 0.472773]\n","719 [D loss: 0.696459, acc.: 65.62%] [G loss: 0.465525]\n","720 [D loss: 0.736722, acc.: 56.25%] [G loss: 0.455555]\n","721 [D loss: 0.723201, acc.: 56.25%] [G loss: 0.414339]\n","722 [D loss: 0.737727, acc.: 62.50%] [G loss: 0.460283]\n","723 [D loss: 0.802336, acc.: 25.00%] [G loss: 0.543297]\n","724 [D loss: 0.810467, acc.: 46.88%] [G loss: 0.511627]\n","725 [D loss: 0.776813, acc.: 53.12%] [G loss: 0.609726]\n","726 [D loss: 0.822185, acc.: 37.50%] [G loss: 0.505511]\n","727 [D loss: 1.036883, acc.: 6.25%] [G loss: 0.482930]\n","728 [D loss: 0.861303, acc.: 6.25%] [G loss: 0.555128]\n","729 [D loss: 0.909673, acc.: 15.62%] [G loss: 0.530945]\n","730 [D loss: 0.849885, acc.: 50.00%] [G loss: 0.518107]\n","731 [D loss: 0.852588, acc.: 12.50%] [G loss: 0.538093]\n","732 [D loss: 0.893509, acc.: 0.00%] [G loss: 0.430690]\n","733 [D loss: 0.925499, acc.: 0.00%] [G loss: 0.607210]\n","734 [D loss: 0.956567, acc.: 0.00%] [G loss: 0.549247]\n","735 [D loss: 0.881129, acc.: 0.00%] [G loss: 0.516778]\n","736 [D loss: 0.862249, acc.: 18.75%] [G loss: 0.505386]\n","737 [D loss: 0.868616, acc.: 46.88%] [G loss: 0.509961]\n","738 [D loss: 0.791406, acc.: 50.00%] [G loss: 0.463739]\n","739 [D loss: 0.797092, acc.: 50.00%] [G loss: 0.556368]\n","740 [D loss: 0.780769, acc.: 50.00%] [G loss: 0.546746]\n","741 [D loss: 0.785540, acc.: 46.88%] [G loss: 0.453240]\n","742 [D loss: 0.773004, acc.: 50.00%] [G loss: 0.479635]\n","743 [D loss: 0.750244, acc.: 50.00%] [G loss: 0.528930]\n","744 [D loss: 0.746549, acc.: 50.00%] [G loss: 0.473107]\n","745 [D loss: 0.781745, acc.: 46.88%] [G loss: 0.536196]\n","746 [D loss: 0.745278, acc.: 50.00%] [G loss: 0.468234]\n","747 [D loss: 0.765989, acc.: 43.75%] [G loss: 0.454736]\n","748 [D loss: 0.798302, acc.: 37.50%] [G loss: 0.514354]\n","749 [D loss: 0.749322, acc.: 50.00%] [G loss: 0.497128]\n","750 [D loss: 0.763904, acc.: 50.00%] [G loss: 0.499116]\n","751 [D loss: 0.738924, acc.: 50.00%] [G loss: 0.490042]\n","752 [D loss: 0.733197, acc.: 50.00%] [G loss: 0.545828]\n","753 [D loss: 0.759793, acc.: 50.00%] [G loss: 0.507793]\n","754 [D loss: 0.743949, acc.: 50.00%] [G loss: 0.415555]\n","755 [D loss: 0.749640, acc.: 50.00%] [G loss: 0.474436]\n","756 [D loss: 0.771854, acc.: 50.00%] [G loss: 0.435620]\n","757 [D loss: 0.751522, acc.: 50.00%] [G loss: 0.422660]\n","758 [D loss: 0.720836, acc.: 50.00%] [G loss: 0.448677]\n","759 [D loss: 0.723270, acc.: 50.00%] [G loss: 0.396668]\n","760 [D loss: 0.739061, acc.: 50.00%] [G loss: 0.471752]\n","761 [D loss: 0.761797, acc.: 50.00%] [G loss: 0.387920]\n","762 [D loss: 0.743421, acc.: 46.88%] [G loss: 0.331076]\n","763 [D loss: 0.779848, acc.: 40.62%] [G loss: 0.517871]\n","764 [D loss: 0.740262, acc.: 50.00%] [G loss: 0.370966]\n","765 [D loss: 0.739873, acc.: 50.00%] [G loss: 0.363525]\n","766 [D loss: 0.721214, acc.: 50.00%] [G loss: 0.363275]\n","767 [D loss: 0.705208, acc.: 50.00%] [G loss: 0.419015]\n","768 [D loss: 0.699895, acc.: 68.75%] [G loss: 0.387347]\n","769 [D loss: 0.719291, acc.: 56.25%] [G loss: 0.386524]\n","770 [D loss: 0.795425, acc.: 50.00%] [G loss: 0.380164]\n","771 [D loss: 0.806625, acc.: 12.50%] [G loss: 0.397684]\n","772 [D loss: 0.711803, acc.: 50.00%] [G loss: 0.413511]\n","773 [D loss: 0.703048, acc.: 53.12%] [G loss: 0.378149]\n","774 [D loss: 0.700499, acc.: 50.00%] [G loss: 0.469458]\n","775 [D loss: 0.722172, acc.: 53.12%] [G loss: 0.392462]\n","776 [D loss: 0.706429, acc.: 59.38%] [G loss: 0.422451]\n","777 [D loss: 0.699408, acc.: 65.62%] [G loss: 0.524050]\n","778 [D loss: 0.705506, acc.: 68.75%] [G loss: 0.421250]\n","779 [D loss: 0.716111, acc.: 53.12%] [G loss: 0.387545]\n","780 [D loss: 0.647397, acc.: 68.75%] [G loss: 0.350987]\n","781 [D loss: 0.700690, acc.: 53.12%] [G loss: 0.356652]\n","782 [D loss: 0.694635, acc.: 62.50%] [G loss: 0.342947]\n","783 [D loss: 0.685162, acc.: 59.38%] [G loss: 0.389978]\n","784 [D loss: 0.695100, acc.: 56.25%] [G loss: 0.409646]\n","785 [D loss: 0.655494, acc.: 68.75%] [G loss: 0.385015]\n","786 [D loss: 0.687083, acc.: 56.25%] [G loss: 0.368637]\n","787 [D loss: 0.696439, acc.: 56.25%] [G loss: 0.317918]\n","788 [D loss: 0.691615, acc.: 65.62%] [G loss: 0.348820]\n","789 [D loss: 0.770643, acc.: 37.50%] [G loss: 0.382909]\n","790 [D loss: 0.791364, acc.: 3.12%] [G loss: 0.398318]\n","791 [D loss: 0.752405, acc.: 53.12%] [G loss: 0.407010]\n","792 [D loss: 0.804669, acc.: 50.00%] [G loss: 0.389148]\n","793 [D loss: 0.816830, acc.: 50.00%] [G loss: 0.412454]\n","794 [D loss: 0.785964, acc.: 53.12%] [G loss: 0.371905]\n","795 [D loss: 0.818209, acc.: 53.12%] [G loss: 0.388227]\n","796 [D loss: 0.789020, acc.: 50.00%] [G loss: 0.324443]\n","797 [D loss: 0.809755, acc.: 53.12%] [G loss: 0.423568]\n","798 [D loss: 0.767294, acc.: 53.12%] [G loss: 0.450414]\n","799 [D loss: 0.743126, acc.: 50.00%] [G loss: 0.404681]\n","800 [D loss: 0.787968, acc.: 50.00%] [G loss: 0.415882]\n","801 [D loss: 0.771455, acc.: 50.00%] [G loss: 0.489326]\n","802 [D loss: 0.748439, acc.: 50.00%] [G loss: 0.441626]\n","803 [D loss: 0.736183, acc.: 50.00%] [G loss: 0.394447]\n","804 [D loss: 0.739116, acc.: 50.00%] [G loss: 0.379492]\n","805 [D loss: 0.741464, acc.: 50.00%] [G loss: 0.362504]\n","806 [D loss: 0.743637, acc.: 50.00%] [G loss: 0.318316]\n","807 [D loss: 0.745898, acc.: 50.00%] [G loss: 0.375030]\n","808 [D loss: 0.743035, acc.: 50.00%] [G loss: 0.396421]\n","809 [D loss: 0.733930, acc.: 50.00%] [G loss: 0.329889]\n","810 [D loss: 0.708856, acc.: 50.00%] [G loss: 0.325191]\n","811 [D loss: 0.711609, acc.: 50.00%] [G loss: 0.349835]\n","812 [D loss: 0.749117, acc.: 50.00%] [G loss: 0.302228]\n","813 [D loss: 0.747133, acc.: 40.62%] [G loss: 0.327283]\n","814 [D loss: 0.719325, acc.: 50.00%] [G loss: 0.358909]\n","815 [D loss: 0.703297, acc.: 50.00%] [G loss: 0.306074]\n","816 [D loss: 0.705672, acc.: 50.00%] [G loss: 0.317550]\n","817 [D loss: 0.710654, acc.: 50.00%] [G loss: 0.346358]\n","818 [D loss: 0.695813, acc.: 50.00%] [G loss: 0.410243]\n","819 [D loss: 0.693001, acc.: 50.00%] [G loss: 0.334182]\n","820 [D loss: 0.681464, acc.: 53.12%] [G loss: 0.330109]\n","821 [D loss: 0.702359, acc.: 53.12%] [G loss: 0.353417]\n","822 [D loss: 0.681064, acc.: 53.12%] [G loss: 0.332878]\n","823 [D loss: 0.745669, acc.: 37.50%] [G loss: 0.395599]\n","824 [D loss: 0.704769, acc.: 50.00%] [G loss: 0.408539]\n","825 [D loss: 0.698132, acc.: 50.00%] [G loss: 0.359636]\n","826 [D loss: 0.711180, acc.: 50.00%] [G loss: 0.376620]\n","827 [D loss: 0.789375, acc.: 12.50%] [G loss: 0.314930]\n","828 [D loss: 0.697375, acc.: 50.00%] [G loss: 0.385841]\n","829 [D loss: 0.737387, acc.: 50.00%] [G loss: 0.352575]\n","830 [D loss: 0.734355, acc.: 50.00%] [G loss: 0.292242]\n","831 [D loss: 0.756789, acc.: 37.50%] [G loss: 0.407023]\n","832 [D loss: 0.755722, acc.: 40.62%] [G loss: 0.344507]\n","833 [D loss: 0.730372, acc.: 50.00%] [G loss: 0.365349]\n","834 [D loss: 0.722952, acc.: 50.00%] [G loss: 0.380275]\n","835 [D loss: 0.736698, acc.: 46.88%] [G loss: 0.394584]\n","836 [D loss: 0.730545, acc.: 50.00%] [G loss: 0.328982]\n","837 [D loss: 0.745680, acc.: 43.75%] [G loss: 0.327502]\n","838 [D loss: 0.745785, acc.: 43.75%] [G loss: 0.307381]\n","839 [D loss: 0.738196, acc.: 43.75%] [G loss: 0.348135]\n","840 [D loss: 0.760944, acc.: 50.00%] [G loss: 0.274382]\n","841 [D loss: 0.756607, acc.: 50.00%] [G loss: 0.331436]\n","842 [D loss: 0.765722, acc.: 40.62%] [G loss: 0.305312]\n","843 [D loss: 0.771820, acc.: 34.38%] [G loss: 0.302158]\n","844 [D loss: 0.740989, acc.: 50.00%] [G loss: 0.307170]\n","845 [D loss: 0.728644, acc.: 50.00%] [G loss: 0.296799]\n","846 [D loss: 0.839078, acc.: 0.00%] [G loss: 0.395472]\n","847 [D loss: 0.754925, acc.: 50.00%] [G loss: 0.333593]\n","848 [D loss: 0.699709, acc.: 50.00%] [G loss: 0.287922]\n","849 [D loss: 0.646230, acc.: 50.00%] [G loss: 0.355222]\n","850 [D loss: 0.678801, acc.: 56.25%] [G loss: 0.288724]\n","851 [D loss: 0.648563, acc.: 65.62%] [G loss: 0.308074]\n","852 [D loss: 0.688265, acc.: 56.25%] [G loss: 0.389602]\n","853 [D loss: 0.667223, acc.: 56.25%] [G loss: 0.335824]\n","854 [D loss: 0.697569, acc.: 50.00%] [G loss: 0.429440]\n","855 [D loss: 0.762190, acc.: 9.38%] [G loss: 0.337706]\n","856 [D loss: 0.659628, acc.: 50.00%] [G loss: 0.383316]\n","857 [D loss: 0.671672, acc.: 50.00%] [G loss: 0.304480]\n","858 [D loss: 0.711124, acc.: 53.12%] [G loss: 0.301544]\n","859 [D loss: 0.659108, acc.: 71.88%] [G loss: 0.364702]\n","860 [D loss: 0.681204, acc.: 71.88%] [G loss: 0.356158]\n","861 [D loss: 0.719286, acc.: 53.12%] [G loss: 0.356373]\n","862 [D loss: 0.730894, acc.: 50.00%] [G loss: 0.389467]\n","863 [D loss: 0.730420, acc.: 50.00%] [G loss: 0.375648]\n","864 [D loss: 0.704697, acc.: 50.00%] [G loss: 0.363655]\n","865 [D loss: 0.713566, acc.: 50.00%] [G loss: 0.317154]\n","866 [D loss: 0.750986, acc.: 6.25%] [G loss: 0.341745]\n","867 [D loss: 0.749642, acc.: 59.38%] [G loss: 0.353309]\n","868 [D loss: 0.735515, acc.: 50.00%] [G loss: 0.403558]\n","869 [D loss: 0.749694, acc.: 50.00%] [G loss: 0.349801]\n","870 [D loss: 0.748760, acc.: 50.00%] [G loss: 0.344234]\n","871 [D loss: 0.750860, acc.: 50.00%] [G loss: 0.366157]\n","872 [D loss: 0.737319, acc.: 50.00%] [G loss: 0.371839]\n","873 [D loss: 0.726422, acc.: 50.00%] [G loss: 0.350374]\n","874 [D loss: 0.728372, acc.: 50.00%] [G loss: 0.334539]\n","875 [D loss: 0.724142, acc.: 53.12%] [G loss: 0.388271]\n","876 [D loss: 0.726977, acc.: 53.12%] [G loss: 0.324481]\n","877 [D loss: 0.728963, acc.: 56.25%] [G loss: 0.360964]\n","878 [D loss: 0.750591, acc.: 50.00%] [G loss: 0.369781]\n","879 [D loss: 0.750351, acc.: 50.00%] [G loss: 0.349381]\n","880 [D loss: 0.718688, acc.: 53.12%] [G loss: 0.377809]\n","881 [D loss: 0.719072, acc.: 53.12%] [G loss: 0.306318]\n","882 [D loss: 0.755318, acc.: 50.00%] [G loss: 0.342756]\n","883 [D loss: 0.750874, acc.: 50.00%] [G loss: 0.304589]\n","884 [D loss: 0.719323, acc.: 50.00%] [G loss: 0.365950]\n","885 [D loss: 0.752953, acc.: 50.00%] [G loss: 0.405344]\n","886 [D loss: 0.753758, acc.: 43.75%] [G loss: 0.335669]\n","887 [D loss: 0.799991, acc.: 21.88%] [G loss: 0.441994]\n","888 [D loss: 0.756899, acc.: 50.00%] [G loss: 0.354296]\n","889 [D loss: 0.776066, acc.: 50.00%] [G loss: 0.340282]\n","890 [D loss: 0.755477, acc.: 50.00%] [G loss: 0.348277]\n","891 [D loss: 0.740743, acc.: 50.00%] [G loss: 0.326888]\n","892 [D loss: 0.740523, acc.: 50.00%] [G loss: 0.355156]\n","893 [D loss: 0.709244, acc.: 50.00%] [G loss: 0.293311]\n","894 [D loss: 0.703039, acc.: 50.00%] [G loss: 0.271250]\n","895 [D loss: 0.714577, acc.: 50.00%] [G loss: 0.342659]\n","896 [D loss: 0.690710, acc.: 50.00%] [G loss: 0.256931]\n","897 [D loss: 0.740133, acc.: 43.75%] [G loss: 0.285080]\n","898 [D loss: 0.760772, acc.: 18.75%] [G loss: 0.357312]\n","899 [D loss: 0.800566, acc.: 6.25%] [G loss: 0.323817]\n","900 [D loss: 0.728398, acc.: 46.88%] [G loss: 0.366042]\n","901 [D loss: 0.710979, acc.: 50.00%] [G loss: 0.315839]\n","902 [D loss: 0.701198, acc.: 50.00%] [G loss: 0.316331]\n","903 [D loss: 0.679922, acc.: 50.00%] [G loss: 0.331039]\n","904 [D loss: 0.695297, acc.: 50.00%] [G loss: 0.329944]\n","905 [D loss: 0.670365, acc.: 56.25%] [G loss: 0.352449]\n","906 [D loss: 0.680718, acc.: 50.00%] [G loss: 0.394613]\n","907 [D loss: 0.676065, acc.: 53.12%] [G loss: 0.291954]\n","908 [D loss: 0.675044, acc.: 50.00%] [G loss: 0.349427]\n","909 [D loss: 0.683242, acc.: 50.00%] [G loss: 0.341365]\n","910 [D loss: 0.687834, acc.: 50.00%] [G loss: 0.303460]\n","911 [D loss: 0.683372, acc.: 53.12%] [G loss: 0.348938]\n","912 [D loss: 0.699252, acc.: 59.38%] [G loss: 0.338252]\n","913 [D loss: 0.705793, acc.: 53.12%] [G loss: 0.355134]\n","914 [D loss: 0.695202, acc.: 50.00%] [G loss: 0.340392]\n","915 [D loss: 0.756459, acc.: 31.25%] [G loss: 0.320986]\n","916 [D loss: 0.721776, acc.: 50.00%] [G loss: 0.362782]\n","917 [D loss: 0.725181, acc.: 50.00%] [G loss: 0.357333]\n","918 [D loss: 0.708662, acc.: 50.00%] [G loss: 0.291852]\n","919 [D loss: 0.738694, acc.: 50.00%] [G loss: 0.321051]\n","920 [D loss: 0.744776, acc.: 40.62%] [G loss: 0.397821]\n","921 [D loss: 0.765694, acc.: 21.88%] [G loss: 0.386734]\n","922 [D loss: 0.764580, acc.: 50.00%] [G loss: 0.297723]\n","923 [D loss: 0.741601, acc.: 50.00%] [G loss: 0.328442]\n","924 [D loss: 0.757023, acc.: 50.00%] [G loss: 0.343947]\n","925 [D loss: 0.777856, acc.: 50.00%] [G loss: 0.320709]\n","926 [D loss: 0.762155, acc.: 50.00%] [G loss: 0.415701]\n","927 [D loss: 0.788760, acc.: 50.00%] [G loss: 0.334897]\n","928 [D loss: 0.735299, acc.: 50.00%] [G loss: 0.392560]\n","929 [D loss: 0.748909, acc.: 50.00%] [G loss: 0.356350]\n","930 [D loss: 0.738357, acc.: 50.00%] [G loss: 0.358031]\n","931 [D loss: 0.732388, acc.: 50.00%] [G loss: 0.306652]\n","932 [D loss: 0.734940, acc.: 50.00%] [G loss: 0.489104]\n","933 [D loss: 0.732865, acc.: 50.00%] [G loss: 0.345693]\n","934 [D loss: 0.720079, acc.: 50.00%] [G loss: 0.367031]\n","935 [D loss: 0.719837, acc.: 50.00%] [G loss: 0.359475]\n","936 [D loss: 0.708123, acc.: 50.00%] [G loss: 0.447576]\n","937 [D loss: 0.691475, acc.: 50.00%] [G loss: 0.401846]\n","938 [D loss: 0.698520, acc.: 50.00%] [G loss: 0.436933]\n","939 [D loss: 0.690836, acc.: 50.00%] [G loss: 0.402454]\n","940 [D loss: 0.668420, acc.: 50.00%] [G loss: 0.405184]\n","941 [D loss: 0.658216, acc.: 50.00%] [G loss: 0.441825]\n","942 [D loss: 0.671983, acc.: 53.12%] [G loss: 0.349707]\n","943 [D loss: 0.669873, acc.: 50.00%] [G loss: 0.406617]\n","944 [D loss: 0.674154, acc.: 50.00%] [G loss: 0.398366]\n","945 [D loss: 0.667797, acc.: 50.00%] [G loss: 0.408458]\n","946 [D loss: 0.656400, acc.: 50.00%] [G loss: 0.360430]\n","947 [D loss: 0.647873, acc.: 62.50%] [G loss: 0.375781]\n","948 [D loss: 0.650457, acc.: 62.50%] [G loss: 0.392428]\n","949 [D loss: 0.652885, acc.: 53.12%] [G loss: 0.390441]\n","950 [D loss: 0.654195, acc.: 62.50%] [G loss: 0.363373]\n","951 [D loss: 0.645118, acc.: 62.50%] [G loss: 0.376154]\n","952 [D loss: 0.654044, acc.: 68.75%] [G loss: 0.334527]\n","953 [D loss: 0.653989, acc.: 59.38%] [G loss: 0.377218]\n","954 [D loss: 0.664106, acc.: 62.50%] [G loss: 0.320000]\n","955 [D loss: 0.647212, acc.: 65.62%] [G loss: 0.374198]\n","956 [D loss: 0.634169, acc.: 81.25%] [G loss: 0.326080]\n","957 [D loss: 0.670804, acc.: 53.12%] [G loss: 0.363288]\n","958 [D loss: 0.662315, acc.: 59.38%] [G loss: 0.353697]\n","959 [D loss: 0.642417, acc.: 75.00%] [G loss: 0.313294]\n","960 [D loss: 0.661368, acc.: 71.88%] [G loss: 0.392996]\n","961 [D loss: 0.671107, acc.: 71.88%] [G loss: 0.382644]\n","962 [D loss: 0.737345, acc.: 37.50%] [G loss: 0.353106]\n","963 [D loss: 0.719974, acc.: 50.00%] [G loss: 0.529209]\n","964 [D loss: 0.728234, acc.: 53.12%] [G loss: 0.420071]\n","965 [D loss: 0.752984, acc.: 50.00%] [G loss: 0.461208]\n","966 [D loss: 0.764823, acc.: 50.00%] [G loss: 0.425965]\n","967 [D loss: 0.761726, acc.: 50.00%] [G loss: 0.416165]\n","968 [D loss: 0.749150, acc.: 50.00%] [G loss: 0.388079]\n","969 [D loss: 0.759514, acc.: 50.00%] [G loss: 0.437241]\n","970 [D loss: 0.719156, acc.: 50.00%] [G loss: 0.364786]\n","971 [D loss: 0.753497, acc.: 50.00%] [G loss: 0.412329]\n","972 [D loss: 0.740390, acc.: 50.00%] [G loss: 0.403177]\n","973 [D loss: 0.744596, acc.: 50.00%] [G loss: 0.368411]\n","974 [D loss: 0.726973, acc.: 50.00%] [G loss: 0.443356]\n","975 [D loss: 0.738730, acc.: 50.00%] [G loss: 0.342268]\n","976 [D loss: 0.742481, acc.: 50.00%] [G loss: 0.373531]\n","977 [D loss: 0.725921, acc.: 50.00%] [G loss: 0.390293]\n","978 [D loss: 0.725882, acc.: 50.00%] [G loss: 0.392048]\n","979 [D loss: 0.715543, acc.: 50.00%] [G loss: 0.361310]\n","980 [D loss: 0.712172, acc.: 50.00%] [G loss: 0.385989]\n","981 [D loss: 0.703320, acc.: 50.00%] [G loss: 0.356032]\n","982 [D loss: 0.705945, acc.: 50.00%] [G loss: 0.360222]\n","983 [D loss: 0.690035, acc.: 50.00%] [G loss: 0.359763]\n","984 [D loss: 0.704813, acc.: 50.00%] [G loss: 0.384246]\n","985 [D loss: 0.680967, acc.: 50.00%] [G loss: 0.354010]\n","986 [D loss: 0.692095, acc.: 50.00%] [G loss: 0.377506]\n","987 [D loss: 0.676794, acc.: 50.00%] [G loss: 0.331358]\n","988 [D loss: 0.692791, acc.: 53.12%] [G loss: 0.342330]\n","989 [D loss: 0.703895, acc.: 53.12%] [G loss: 0.312286]\n","990 [D loss: 0.667583, acc.: 53.12%] [G loss: 0.335770]\n","991 [D loss: 0.666006, acc.: 56.25%] [G loss: 0.374629]\n","992 [D loss: 0.637382, acc.: 59.38%] [G loss: 0.372967]\n","993 [D loss: 0.651457, acc.: 53.12%] [G loss: 0.306011]\n","994 [D loss: 0.691581, acc.: 53.12%] [G loss: 0.316610]\n","995 [D loss: 0.703359, acc.: 62.50%] [G loss: 0.327328]\n","996 [D loss: 0.671466, acc.: 68.75%] [G loss: 0.336550]\n","997 [D loss: 0.721507, acc.: 56.25%] [G loss: 0.337286]\n","998 [D loss: 0.695132, acc.: 59.38%] [G loss: 0.355862]\n","999 [D loss: 0.681179, acc.: 68.75%] [G loss: 0.281666]\n"],"name":"stdout"}]}]}